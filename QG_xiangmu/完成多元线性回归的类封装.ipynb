{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "505dac01",
   "metadata": {},
   "source": [
    "# 完成多元线性回归的类封装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0eec81f",
   "metadata": {},
   "source": [
    "##### 完成项目的目的：熟练理解Kmean里面代码的实际含义，而不是只会调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0045acc0",
   "metadata": {},
   "source": [
    "### 知识点补充：sklearn的了解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e2e7dca9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit_learn in c:\\users\\17123\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\17123\\anaconda3\\lib\\site-packages (from scikit_learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\17123\\anaconda3\\lib\\site-packages (from scikit_learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\17123\\anaconda3\\lib\\site-packages (from scikit_learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\17123\\anaconda3\\lib\\site-packages (from scikit_learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit_learn\n",
    "#安装一下这个学习包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d3f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa29bf91",
   "metadata": {},
   "source": [
    " > 要求：代码实现解析解求解和梯度下降法求解 参考sklearn接口形式 不允许调用机器学习库，仅可使用numpy\n",
    "以波士顿房价数据集为例，划分训练集，测试集，并完成数据分析和预处理 完成模型训练并予以评价分析\n",
    "结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba856aa2",
   "metadata": {},
   "source": [
    "介绍一下sklearn：<br>\n",
    "1.sklearn是什么东西<br>\n",
    "scikit-learn（通常简称为 sklearn）是一个用于机器学习和数据挖掘的开源 Python 库。它包含了各种用于分类、回归、聚类、降维、模型选择、预处理等任务的工具和算法。<br>\n",
    "scikit-learn 提供了简单一致的 API，易于学习和使用。它内置了许多常用的机器学习算法和工具，如支持向量机、随机森林、k-近邻、K-means 等。此外，它还提供了丰富的数据集和模型评估工具，帮助用户快速搭建机器学习流水线并评估模型性能。\n",
    "scikit-learn 是基于 NumPy、SciPy 和 matplotlib 等 Python 科学计算库构建的，能够与这些库很好地集成。它是机器学习领域中最受欢迎和广泛使用的库之一，被广泛应用于学术研究和工业应用中。<br>\n",
    "2.那这个库里面是不是内置了一些数据集的例子来提供学者学习<br>\n",
    "是的，scikit-learn 库内置了一些常用的标准数据集，这些数据集常被用来测试和验证机器学习算法的性能。这些数据集包括了各种类型的数据，涵盖了不同的应用场景，例如分类、回归、聚类等。<br>\n",
    "一些常见的内置数据集包括：\n",
    "1. **Iris 数据集**：包含了 150 个样本，每个样本有 4 个特征，用于鸢尾花的分类任务。\n",
    "2. **Digits 数据集**：包含了 1797 张 8x8 像素的手写数字图像，用于手写数字的识别任务。\n",
    "3. **Wine 数据集**：包含了 178 个样本，每个样本有 13 个特征，用于葡萄酒的分类任务。\n",
    "4. **Boston 房价数据集**：包含了 506 个样本，每个样本有 13 个特征，用于房价预测的回归任务。\n",
    "5. **Breast cancer 数据集**：包含了 569 个样本，每个样本有 30 个特征，用于乳腺癌的分类任务。\n",
    "这些数据集可以通过 scikit-learn 的 API 直接获取，方便了机器学习算法的测试和学习。同时，这些数据集还常被用来进行教学和研究，以帮助学者更好地理解和掌握机器学习算法的原理和应用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295936c6",
   "metadata": {},
   "source": [
    "不能调用机器学习库，则fit，predict函数要自己写"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3f7ad5",
   "metadata": {},
   "source": [
    "### 代码部分：以下是GPT写的，网上找的知识都是零散的知识点，没有系统的写法。自己在这里只是进行解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0cab346",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\17123\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:303: UserWarning: Multiple active versions of the dataset matching the name boston exist. Versions may be fundamentally different, returning version 1.\n",
      "  warn(\n",
      "C:\\Users\\17123\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 数据预处理和分析\n",
    "from sklearn.datasets import fetch_openml# 加载波士顿房价数据集\n",
    "boston = fetch_openml(name='boston')\n",
    "#这个过时了from sklearn.datasets import load_boston   载入波士顿房价数据集\n",
    "from sklearn.model_selection import train_test_split  # 划分训练集和测试集的函数\n",
    "from sklearn.preprocessing import StandardScaler  # 数据标准化函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba1a5d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义多元线性回归类\n",
    "class LinearRegression:\n",
    "    # 初始化函数，设置是否包含截距项,\n",
    "    #截距项就是网课中的b，默认要进行拟合不为0\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        self.fit_intercept = fit_intercept  # 设置是否拟合截距项\n",
    "        self.weights = None  # 初始化权重参数\n",
    "        \n",
    "    # 训练模型的方法,这里定义fit方法，利用了\n",
    "    def fit(self, X, y, method='analytical', learning_rate=0.01, n_iterations=1000):\n",
    "        #分析方法的参数默认为analytical，学习率设置为0.01，迭代次数为1000次\n",
    "        \"\"\"X = np.hstack((np.ones((X.shape[0], 1)), X))：这行代码是在特征矩阵 X 的最左侧添加一列全为1的截距项。\n",
    "        np.ones((X.shape[0], 1)) 用于生成一个形状为 (样本数量, 1) 的矩阵，其中所有元素都是1。\n",
    "        然后使用 np.hstack() 函数将这一列截距项添加到特征矩阵 X 的左侧。\n",
    "        这样做的目的是为了在特征矩阵中引入一个常数项，以便模型能够学习到一个截距参数，从而更好地拟合数据。\"\"\"\n",
    "        if self.fit_intercept:  # 如果包含截距项\n",
    "            X = np.hstack((np.ones((X.shape[0], 1)), X))  # 添加全为1的一列作为截距项\n",
    "        \n",
    "        \"\"\"解析解方法的解释：解析解方法的原理基于最小二乘法和线性代数的基本原理。\n",
    "        在线性回归中，我们的目标是找到一组权重 w，使得模型的预测值与真实值之间的损失最小化。\n",
    "        解析解方法通过数学推导直接求解这组最优权重，而不需要使用迭代算法进行优化。\"\"\"\n",
    "        \"\"\"解释：解析解方法的代码含义\n",
    "            X.T.dot(X)：计算特征矩阵 \n",
    "            X 的转置矩阵 X T与自身的乘积，得到一个方阵，通常称为 Gram 矩阵或协方差矩阵。\n",
    "            np.linalg.inv(X.T.dot(X))：对上一步得到的方阵求逆矩阵。\n",
    "            X.T.dot(y)：计算特征矩阵 X 的转置矩阵 X T与目标变量 y 的乘积。\n",
    "            np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)：将步骤 2 和步骤 3 的结果相乘，然后与 y 相乘，得到最优权重 w。\"\"\"\n",
    "        if method == 'analytical':  # 如果选择解析解方法\n",
    "            self.weights = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)  # 使用解析解计算权重\n",
    "            \"\"\"解释梯度下降算法的代码：\n",
    "            这段代码是使用梯度下降法来训练线性回归模型，其基本原理是通过迭代更新权重，使得损失函数逐渐减小，最终找到最优的权重值。\n",
    "            self.weights = np.zeros(X.shape[1])：这行代码初始化了模型的权重，将其设为全零。\n",
    "            权重的数量等于特征的数量加上一个截距项（如果模型包含截距项的话），所以使用 X.shape[1] 来确定权重的长度。\n",
    "            for _ in range(n_iterations):：这行代码是一个循环，用于执行多次迭代更新权重的过程。\n",
    "            n_iterations 表示迭代的次数，即更新权重的总次数。\n",
    "            gradients = -2 * X.T.dot(y - X.dot(self.weights))：这行代码计算了损失函数关于权重的梯度。\n",
    "            梯度是损失函数关于参数的变化率，通过梯度可以确定损失函数的下降方向。这里使用了损失函数的梯度下降法的一阶导数，具体推导过程可以参考梯度下降法的原理。\n",
    "            self.weights -= learning_rate * gradients：这行代码根据学习率和梯度更新了权重。\n",
    "            学习率决定了参数更新的步长，梯度指示了参数更新的方向。通过将梯度乘以学习率，我们可以控制每次参数更新的大小。\n",
    "            然后将得到的更新量减去当前权重，以更新权重值。\n",
    "            循环重复执行步骤 3 和步骤 4，直到达到设定的迭代次数 n_iterations，或者损失函数收敛到一个可接受的程度。\n",
    "            在每次迭代中，权重都会根据梯度的信息进行调整，使得损失函数逐渐减小，最终达到最优权重值\"\"\"\n",
    "        elif method == 'gradient_descent':  # 如果选择梯度下降法\n",
    "            self.weights = np.zeros(X.shape[1])  # 初始化权重为0\n",
    "            for _ in range(n_iterations):  # 迭代更新权重\n",
    "                gradients = -2 * X.T.dot(y - X.dot(self.weights))  # 计算梯度\n",
    "                self.weights -= learning_rate * gradients  # 根据学习率更新权重\n",
    "                \n",
    "    # 对新数据进行预测的方法\n",
    "    def predict(self, X):\n",
    "        if self.fit_intercept:  # 如果包含截距项\n",
    "            X = np.hstack((np.ones((X.shape[0], 1)), X))  # 添加全为1的一列作为截距项\n",
    "        return X.dot(self.weights)  # 返回预测结果\n",
    "    \n",
    "    # 计算模型得分的方法\n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)  # 预测结果\n",
    "        return 1 - ((y - y_pred) ** 2).sum() / ((y - y.mean()) ** 2).sum()  # 返回R^2得分\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2061f414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集得分: 0.7508856358979673\n",
      "测试集得分: 0.6687594935356311\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "X = boston.data  # 特征矩阵\n",
    "y = boston.target  # 目标向量\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()  # 初始化标准化器\n",
    "X_scaled = scaler.fit_transform(X)  # 对特征矩阵进行标准化处理\n",
    "\n",
    "# 划分训练集和测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 模型训练\n",
    "model = LinearRegression()  # 初始化线性回归模型\n",
    "model.fit(X_train, y_train, method='analytical')  # 训练模型，可以选择解析解或梯度下降法\n",
    "\n",
    "# 模型评价\n",
    "train_score = model.score(X_train, y_train)  # 计算训练集得分\n",
    "test_score = model.score(X_test, y_test)  # 计算测试集得分\n",
    "\n",
    "# 打印结果\n",
    "print(\"训练集得分:\", train_score)  # 打印训练集得分\n",
    "print(\"测试集得分:\", test_score)  # 打印测试集得分\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec04cfd2",
   "metadata": {},
   "source": [
    "### 要改善的地方:<br>\n",
    "问题：<br>\n",
    "1.不知道解析解方法的原理（最小二乘法），不知道解析解方法对应的代码的原理<br>\n",
    "2.不知道添加全为1的一列作为截距项的这个的原理<br>\n",
    "3.稍微知道梯度下降方法的原理，但是不知道对应的代码的含义<br>\n",
    "4.不知道模型得分的方法的算法原理是什么"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237b0bd",
   "metadata": {},
   "source": [
    "### 学到的东西：<br>\n",
    "1.学到了sklearn这个是什么东西<br>\n",
    "2.学会了套代码：用解析解方法和梯度下降算法进行多元线性回归的方法<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
